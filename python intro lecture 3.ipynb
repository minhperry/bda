{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Random Number Generators in PyTorch\n",
    "Key takeaways from last lecture:\n",
    "* random numbers in your code are never truly random!\n",
    "* think about where your pseudo random numbers come from and how you can control their generation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default random number generator in Python\n",
    "It's the Mersenne Twister!\n",
    "* just don't use the distributions, use the numpy equivalent instead (e.g., `_rng.choice(...)`, `_rng.shuffle(_arr)`)\n",
    "* functions for sequences: `random.choice`, `random.shuffle`, `random.sample`\n",
    "    * use  the equivalent numpy functions or draw a random index using it\n",
    "* still, if you *need* reproducible code, you need to seed this RNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import secrets\n",
    "\n",
    "_my_python_seed = secrets.randbits(128)  # save this seed for reproducibilty\n",
    "random.seed(_my_python_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caveats from the [python docs](https://docs.python.org/3/library/random.html):\n",
    "> By reusing a seed value, the same sequence should be reproducible from run to run as long as multiple threads are not running.\n",
    "\n",
    "> Most of the random moduleâ€™s algorithms and seeding functions are **subject to change** across Python versions [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default random number generator in PyTorch\n",
    "It's the Mersenne Twister! (I kid you not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeding pseudo random number generators in PyTorch\n",
    "There is a convenience function provided by torch to seed its global random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# seed the Mersenne Twister on the CPU and Philox generator(s) on the GPU(s)\n",
    "torch.manual_seed(1717800298)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find in old documentation or other libraries' use of PyTorch the following additional statements. However, `torch.manual_seed()` will seed the generators on the GPU(s) as well.\n",
    "```\n",
    "# seed the generator on a single GPU\n",
    "torch.cuda.manual_seed(_my_manual_single_cuda_seed)\n",
    "\n",
    "# or seed the different generators on multiple GPUs\n",
    "torch.cuda.manual_seed_all(_my_manual_multi_cuda_seed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch uses CUDA to run on nvida graphics cards. The separate pseudo RNGs there use the `Philox_4x32_10` generator.\n",
    "The [documentation](https://docs.nvidia.com/cuda/curand/device-api-overview.html#bit-generation-3) of the `curand` package (part of nvidia's CUDA toolkit) recommends:\n",
    "> For the highest quality parallel pseudorandom number generation, each experiment should be assigned a unique seed value. Within an experiment, each thread of computation should be assigned a unique id number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training script, we create a convenience function that takes a seed and makes PyTorch run *as deterministic as possible*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src.utils\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def seed_torch(seed, reproducible:bool = False):\n",
    "    np.random.seed(seed % (2**32-1))  # numpy global rng \n",
    "    torch.manual_seed(seed % (2**32-1))  # torch global rng (CPU & CUDA)\n",
    "    random.seed(seed % (2**32-1))  # python global rng (MT)\n",
    "\n",
    "    if reproducible:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to seed the dataloaders or provide them an instance of `torch.Generator`. The [PyTorch docs](https://pytorch.org/docs/stable/notes/randomness.html) recommend the following code. We are going to refrain from using worker threads for the dataloader, so we are only going to pass a generator instance later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: Randomly initializing weights\n",
    "Before we start training our neural network, all its weights (& biases) have to be initialized. This initialization can have a significant impact on the final performance of the trained network. PyTorch automatically performs standard initialization with random numbers. There is some research into more sophisticated initialization strategies (about the distribution to draw from), depending on the network architecture, but we are going to stick with PyTorch's standard initialization scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only problem? This initialization function currently *does not support* a `generator` keyword. This means, the random numbers come from PyTorch's global RNG. So we are going to *reimplement* this function. Our only change is to allow passing through a `generator` argument to the unform sampling function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src.utils\n",
    "\n",
    "import warnings\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.init import _calculate_correct_fan, calculate_gain\n",
    "\n",
    "def kaiming_uniform_(\n",
    "    tensor: torch.Tensor, a: float = 0, mode: str = 'fan_in', nonlinearity: str = 'leaky_relu', generator: torch.Generator | None = None\n",
    "):\n",
    "    \"\"\"Reimplementation of torch.nn.init.kaiming_uniform_ with generator arg\"\"\"\n",
    "    if torch.overrides.has_torch_function_variadic(tensor):\n",
    "        return torch.overrides.handle_torch_function(\n",
    "            kaiming_uniform_,\n",
    "            (tensor,),\n",
    "            tensor=tensor,\n",
    "            a=a,\n",
    "            mode=mode,\n",
    "            nonlinearity=nonlinearity)\n",
    "\n",
    "    if 0 in tensor.shape:\n",
    "        warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
    "        return tensor\n",
    "    fan = _calculate_correct_fan(tensor, mode)\n",
    "    gain = calculate_gain(nonlinearity, a)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    bound = math.sqrt(3.0) * std  # Calculate uniform bounds from standard deviation\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(-bound, bound, generator=generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: randomly splitting your data into train and validation splits\n",
    "It is common practice to create a hold-out set for monitoring the training process for signs of overfitting and potentially selecting parameters on a trained network. This hold-out set is called the validation set and typically created by randomly splitting the whole dataset available for training into one smaller subset used for training and another as the hold-out subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "_split_gen = torch.Generator()\n",
    "_split_gen.manual_seed(2080986636)\n",
    "\n",
    "_train_data, _val_data = random_split(range(10), lengths=[0.8, 0.2], generator=_split_gen)\n",
    "_train_data.indices, _val_data.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training today, we are going to need to fix the global seeds and create one local `torch.Generator` instance to pass around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random seeds\n",
    "import secrets\n",
    "\n",
    "_global_seed = secrets.randbits(128) % (2**32-1)\n",
    "_local_seed = secrets.randbits(128) % (2**32-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these would also have to be tracked in your tool\n",
    "print(f\"Set all global seeds to: {_global_seed}\")\n",
    "print(f\"Set the local torch seed to {_local_seed}\")\n",
    "\n",
    "# seed our generators for reproducibility\n",
    "seed_torch(_global_seed, reproducible=True)\n",
    "_rng_cpu = torch.Generator()\n",
    "_rng_cpu.manual_seed(_local_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network in PyTorch\n",
    "Selecting a suitable model architecture depends on the type of data we have and the task it should learn. \n",
    "\n",
    "Today, we are going to train an image classifier on the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The CIFAR10 dataset consists of 60,000 RGB color images (32x32) in 10 classes:  `plane`, `car`, `bird`, `cat`, `deer`, `dog`, `frog`, `horse`, `ship`, `truck`. PyTorch conveniently allows us to directly download this dataset using `torchvision.datasets.CIFAR10`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is already split into 50,000 training and 10,000 testing samples. As the convenience function directly creates a pytorch `dataset` object, we need to provide the call with the transformations that we would like to apply. In this case, we merely need to normalize the data and turn them into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# calculated beforehand\n",
    "_cifar_means = (0.4914, 0.4822, 0.4465)\n",
    "_cifar_stds = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_cifar_means, _cifar_stds)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will take a while on first executing it, because the dataset is downloaded in the background\n",
    "\n",
    "import torchvision\n",
    "\n",
    "_train_data_full = torchvision.datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=_transform)\n",
    "\n",
    "_test_data_full = torchvision.datasets.CIFAR10(root=\"../data\", train=False, download=True, transform=_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "Next, we need a model. We are going to use a simplified version of the well-known `ResNet` family. This architecture uses convolutions and pooling operations in different blocks. At the end, it has a fully-connected layer for the classification. Our version `ResNet9` uses the modified weight initalization that we have introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src.models\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv_bn(channels_in, channels_out, kernel_size=3, stride=1, padding='same', bn=True, activation=True):\n",
    "    op = [\n",
    "            nn.Conv2d(channels_in, channels_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "    ]\n",
    "    if bn:\n",
    "        op.append(nn.BatchNorm2d(channels_out))\n",
    "    if activation:\n",
    "        op.append(nn.ReLU(inplace=True))\n",
    "    return nn.Sequential(*op)\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(Residual, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.module(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, rng:torch.Generator, num_class:int = 10, **kwargs):\n",
    "        super(ResNet9, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            conv_bn(3, 64, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            conv_bn(64, 128, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.MaxPool2d(2),\n",
    "            Residual(nn.Sequential(\n",
    "                conv_bn(128, 128),\n",
    "                conv_bn(128, 128),\n",
    "            )),\n",
    "\n",
    "            conv_bn(128, 256, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            conv_bn(256, 256, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.MaxPool2d(2),\n",
    "            Residual(nn.Sequential(\n",
    "                conv_bn(256, 256),\n",
    "                conv_bn(256, 256),\n",
    "            )),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, num_class, bias=False),\n",
    "        )\n",
    "\n",
    "        self.reset_parameters(rng)\n",
    "\n",
    "    def reset_parameters(self, rng: torch.Generator):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                kaiming_uniform_(m.weight, nonlinearity=\"relu\", generator=rng)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                kaiming_uniform_(m.weight, nonlinearity=\"linear\", generator=rng)\n",
    "                # we have disabled the bias term in the linear layers, no need to init\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = ResNet9(rng=_rng_cpu, num_class=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training\n",
    "To train our model, we need an optimizer, that will modify the weights according to our models previous performance. We are going to use simple *stochastic gradient descent*. It needs three hyperparameters: learning rate, momentum and weight decay rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "_learning_rate = 1e-3\n",
    "_momentum = 0.9\n",
    "_weight_decay = 1e-3\n",
    "_optimizer = optim.SGD(_model.parameters(), lr=_learning_rate, momentum=_momentum, nesterov=True, weight_decay=_weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we need to measure how well the network is doing at its task. We are going to use `CrossEntropyLoss` to compare class predictions with the true class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, onto the training! We define a function `fit` that takes our training data and trains our model `epoch_num` many times on it. This is also where we can move our computations to a GPU, if we have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src.train\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def fit(data, model, optimizer, criterion, epoch_num:int, batch_size:int, device, dl_rng):\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    _is_cuda = device.type == 'cuda'\n",
    "\n",
    "    _train_loader = DataLoader(dataset=data, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=0, pin_memory=_is_cuda, generator=dl_rng)\n",
    "    \n",
    "    _epoch_loss_train = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for _epoch in range(epoch_num):\n",
    "        _loss = 0\n",
    "        for _inputs, _labels in _train_loader:\n",
    "            _inputs = _inputs.to(device)\n",
    "            _labels = _labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            _outputs = model(_inputs)\n",
    "\n",
    "            _train_loss = criterion(_outputs, _labels)\n",
    "            _train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            _loss += _train_loss.item()\n",
    "\n",
    "        _loss /= len(_train_loader)\n",
    "\n",
    "        print(f\"Epoch {_epoch+1}/{epoch_num}, average train_loss: {_loss:.4f}\")\n",
    "        _epoch_loss_train.append(_loss)\n",
    "\n",
    "    return _epoch_loss_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any trained neural network typically performs best on the data that it was trained on. To check how well it would do with new data, we are also going to run our model on separate data from the same distribution. This is our *test* set. We define another function for this purpose, which we call `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, model, criterion, batch_size:int, device, dl_rng):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    _is_cuda = device.type == 'cuda'\n",
    "    \n",
    "    _loader = DataLoader(dataset=data, batch_size=batch_size, drop_last=False, shuffle=False, num_workers=0, pin_memory=_is_cuda, generator=dl_rng)\n",
    "    \n",
    "    _preds = []\n",
    "    _pred_errs = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for _inputs, _labels in _loader:\n",
    "        _inputs = _inputs.to(device)\n",
    "        _labels = _labels.to(device)\n",
    "\n",
    "        _outputs = model(_inputs)\n",
    "\n",
    "        _pred_loss = criterion(_outputs, _labels)\n",
    "\n",
    "        _preds.append(_outputs.softmax(dim=1))\n",
    "        _pred_errs.append(_pred_loss)\n",
    "\n",
    "    return torch.cat(_preds), torch.cat(_pred_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to try this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define the last hyperparameters\n",
    "_epoch_num = 22\n",
    "_batch_size = 500\n",
    "\n",
    "# train\n",
    "_epoch_loss = fit(_train_data_full, _model, _optimizer, _criterion, _epoch_num, _batch_size, _device, _rng_cpu)\n",
    "\n",
    "# test\n",
    "_test_criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "_preds, _pred_errs = predict(_test_data_full, _model, _test_criterion, _batch_size, _device, _rng_cpu)\n",
    "\n",
    "\n",
    "print(f\"\\nEpoch {_epoch_num}/{_epoch_num}, average test_loss: {_pred_errs.sum()/(len(_test_data_full)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model for later (optional)\n",
    "#torch.save(_model.state_dict(), \"./models/CIFAR10_22.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(_epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the predicted classes, we have to find the index of the highest value in the predictions vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload our model\n",
    "_rng_model = torch.Generator()\n",
    "_rng_model.manual_seed(4072885555)\n",
    "_saved_net = ResNet9(rng=_rng_model)\n",
    "_saved_net.load_state_dict(\"./models/CIFAR10_22.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
